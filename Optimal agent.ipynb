{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afab7cc2-57cc-460d-8868-0da9e3b7eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843d81d-59e5-4ee6-b821-3a73cde8377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for algorithm and wealth\n",
    "# Wt starting parameters\n",
    "# Total lifespan to use portfolio\n",
    "T = 5\n",
    "# timestep\n",
    "dt=1/252\n",
    "# total number of days in the lifespan\n",
    "total_days = int(T/dt)\n",
    "# original investment\n",
    "W_0 = 50000\n",
    "\n",
    "# mean drift of risky investment\n",
    "mu = 0.1\n",
    "# risk free rate of return\n",
    "r= 0.02\n",
    "# volatility of risky investment\n",
    "sigma = 0.2\n",
    "# level of risk aversion\n",
    "gamma = 4\n",
    "# utility discount rate\n",
    "rho = 0.05\n",
    "# bequest\n",
    "e = 0.01\n",
    "\n",
    "# formula for calculating how the wealth process develops every timestep\n",
    "def get_dW(self,W, pi, mu, r, c,dt, sigma):\n",
    "    dZ = np.random.normal()*(np.sqrt(dt))\n",
    "    drift = W*(pi*(mu-r)+r-c)\n",
    "    dw = drift*dt + pi*sigma*W*dZ\n",
    "    return dw\n",
    "\n",
    "def get_reward(u, gamma):\n",
    "    if gamma != 1:\n",
    "        reward = (u**(1-gamma))/(1-gamma)\n",
    "    else:\n",
    "        reward = np.log(u)\n",
    "        \n",
    "    reward*=np.exp(-rho*t*dt)\n",
    "\n",
    "    return reward\n",
    "\n",
    "def mertons_frac(mu,r,sigma,gamma):\n",
    "    top = mu-r\n",
    "    bottom = gamma*sigma**2\n",
    "    frac = top/bottom\n",
    "    return frac\n",
    "\n",
    "def get_v(rho, gamma, pi, mu, r):\n",
    "    v = (rho - (1-gamma)*(pow(mu-r,2)/(2*gamma*pow(sigma,2))+r))/gamma\n",
    "    return v\n",
    "\n",
    "\n",
    "def cW_T(v,T,t):\n",
    "    if v!= 0:\n",
    "        c = v/(1+(v*e-1)*np.exp(-v*(T-t/252)*gamma))\n",
    "    else:\n",
    "        c = 1/(T-t/252 + e)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cea911-b28c-448d-88ad-1288daf3e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent parameters\n",
    "\n",
    "class Merton:\n",
    "        def __init__(self):\n",
    "            # vector of time statespace  with \n",
    "            # time as a percentage of time left in episode\n",
    "            self.time_states = [x/100 for x in range(101)]\n",
    "            # vector of wealth statespace with different \n",
    "            # defined as different thresholds for amount of total wealth \n",
    "            # from 0 <= x_n < x_n+1 < 100000 : x = 10000*n: n = 0,1,2,...\n",
    "            self.wealth_states = [y*10**4 for y in range(10)]\n",
    "            \n",
    "\n",
    "\n",
    "# number of episodes \n",
    "num_episodes = 50000\n",
    "\n",
    "# records\n",
    "ep_rewards = []\n",
    "total_consumed  = []\n",
    "agent = Merton()\n",
    "c_values = []\n",
    "pi = mertons_frac(mu,r,sigma,gamma)\n",
    "if pi>1:\n",
    "    pi = 1\n",
    "v= get_v(rho, gamma, pi, mu, r)\n",
    "final_wealth = []\n",
    "\n",
    "\n",
    "# # simulating\n",
    "for episode in range(num_episodes):\n",
    "    episode_consumption = []\n",
    "    if (episode+1)%100 ==0:\n",
    "        print(episode+1)\n",
    "    # reset environment\n",
    "    # episode rewards \n",
    "    G = 0\n",
    "    # starting wealth\n",
    "    wealth = W_0\n",
    "    for t in range(total_days):\n",
    "        c = cW_T(v,T,t)\n",
    "        c_values.append(c)\n",
    "        # update wealth\n",
    "        dW = get_dW(wealth,t,pi,mu,r,c,dt,sigma)\n",
    "        # print(dW,c)\n",
    "        wealth += dW\n",
    "        episode_consumption.append(c*wealth*dt)\n",
    "        # reward\n",
    "        reward = get_reward(c*wealth*dt,gamma)\n",
    "        if (t+1)== total_days: reward+= get_reward(wealth,gamma)\n",
    "        G += reward\n",
    "       \n",
    "    ep_rewards.append(G)\n",
    "    final_wealth.append(wealth)\n",
    "    total_consumed.append(sum(episode_consumption))\n",
    "    \n",
    "tally = \"Total money consumed: {:.2f}\\n\\\n",
    "Total money leftover: {:.2f}\"\n",
    "\n",
    "MoneyC = np.mean(total_consumed)\n",
    "MoneyL = np.mean(final_wealth)\n",
    "print(tally.format(MoneyC,MoneyL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee550ac-5533-4b4e-b741-5213e1430cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot results\n",
    "\n",
    "mean_consumption = [np.mean(episode_consumption[n-30:n]) if n > 30 else np.mean(episode_consumption[:n]) \n",
    "               for n in range(1, len(episode_consumption))] \n",
    "\n",
    "x = np.linspace(0,1,len(mean_consumption))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(x,mean_consumption)\n",
    "plt.title('Consumption Over Time')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('consumption')\n",
    "plt.savefig('Merton Consumption.png')\n",
    "plt.show()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
